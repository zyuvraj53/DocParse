# ğŸ§  Resume Parser & Candidate Fit Scorer

An advanced Python module that extracts structured resume data from PDF files and ranks candidates based on job fit. It uses regex, NLP, and heuristic rules to analyze resume content, anonymize personal details, and calculate job matching scores.

---

## âœ¨ Key Features

- ğŸ“„ **Resume Text Extraction** from PDFs
- ğŸ§  **Entity Extraction**:
  - Personal Info (Name, Email, Phone, LinkedIn, GitHub)
  - Education (Degree, Institution, Dates)
  - Experience (Company, Role, Dates, Achievements)
  - Skills (Technical & Soft)
  - Certifications, Languages
- ğŸ” **Anonymization** of PII for bias-free review
- ğŸ“Š **Fit Score Calculator** based on job description
- ğŸ“Œ **Ranking & Shortlisting** based on fit score
- ğŸ“ **Batch Processing** of multiple resumes
- âœ… Outputs structured JSON data

---

## ğŸ§° Main Workflow: `main()`

### Purpose:

Tests the `EnhancedPDFExtractor` class by:

- Loading a sample job description
- Processing one test resume PDF
- Running batch processing on all resumes in `UPLOADS_DIR`
- Saving results with anonymized data and fit scores

### Calls:

- `EnhancedPDFExtractor.process_pdf()` â€“ handles single file processing
- `EnhancedPDFExtractor.batch_process()` â€“ handles batch processing

---

## ğŸ§  Class: `EnhancedPDFExtractor`

Main class that coordinates extraction, parsing, scoring, anonymization, and saving.

### Key Methods & Their Responsibilities:

---

### ğŸ” `extract_text_from_pdf(pdf_path)`

- Uses `pdfplumber` to read text from PDF
- Returns text and page count

---

### ğŸ“Š `classify_document(filename, text)`

- Identifies if the document is a resume or other type
- Returns type and confidence score

---

### ğŸ§± `extract_entities(text, filename)`

- Central method to extract all resume components:
  - Calls sub-methods:
    - `_extract_personal_info()`
    - `_extract_education()`
    - `_extract_experience()`
    - `_extract_skills()`
    - `_extract_certifications()`
    - `_extract_languages()`
  - Returns full structured resume entity dictionary

---

### ğŸ‘¤ `_extract_personal_info()`

- Extracts name, phone, email, LinkedIn, GitHub, location

---

### ğŸ“ `_extract_education()`

- Detects and parses Education section
- Extracts degree, institution, and dates

---

### ğŸ’¼ `_extract_experience()`

- Extracts Company, Designation, Dates, Achievements
- Uses bullet points or line breaks to separate jobs

---

### ğŸ§‘â€ğŸ’» `_extract_skills()`

- Categorizes skills as Technical or Soft
- Matches from predefined lists in both the resume and job description

---

### ğŸ… `_extract_certifications()`

- Looks for known certification headings and extracts valid lines

---

### ğŸ—£ï¸ `_extract_languages()`

- Identifies languages known or mentioned

---

### ğŸ”’ `anonymize_entities(entities)`

- Redacts PII (Name, Email, Phone, LinkedIn, GitHub, Location)
- Replaces institutions and company names with placeholders

---

### ğŸ§® `calculate_fit_score(entities, job_description)`

- Assigns weights and scores to resume based on JD match
- Criteria:
  - Skills Match (40%)
  - Experience Relevance (30%)
  - Education Match (20%)
  - Tenure Stability (5%)
  - Growth Trajectory (5%)
- Returns dictionary of scores

---

### ğŸ“Š `rank_candidates(candidates, job_description)`

- Ranks all candidates by `total_fit` score
- Adds `rank` field to each

---

### âœ… `shortlist_candidates(ranked_candidates, threshold=70, max_candidates=None)`

- Selects top candidates above threshold
- Flags each as `shortlisted: True` or `False`

---

### ğŸ“ `process_pdf(pdf_path, job_description=None, anonymize=False)`

#### Purpose:

Main function for processing a single resume

#### Steps:

1. Extracts text from PDF
2. Classifies document
3. Parses resume entities
4. Anonymizes (optional)
5. Scores against JD (if provided)
6. Returns structured dictionary

#### Calls:

- `extract_text_from_pdf()`
- `classify_document()`
- `extract_entities()`
- `anonymize_entities()`
- `calculate_fit_score()`

---

### ğŸ“¦ `batch_process(pdf_dir, job_description=None, anonymize=False)`

#### Purpose:

Process all PDFs in directory

#### Steps:

1. Finds all `.pdf` files
2. Calls `process_pdf()` on each
3. Saves:
   - Raw results
   - Ranked results (if JD is given)

---

## ğŸ“ Project Structure

```
your_project/
â”‚
â”œâ”€â”€ uploads_resumes/           # Input resumes in PDF format
â”œâ”€â”€ processed_results/         # JSON outputs
â”œâ”€â”€ extractor_module.py        # Contains EnhancedPDFExtractor class
â””â”€â”€ README.md                  # This documentation
```

---

## âœ… Setup Instructions

1. **Install dependencies**:

```bash
pip install pdfplumber spacy
python -m spacy download en_core_web_sm
```

2. **Prepare directories**:

- Place resumes in `uploads_resumes/`

3. **Run main script**:

```bash
python extractor_module.py
```

---

## ğŸ“Š Sample Output (JSON)

```json
{
  "entities": {
    "personal_info": {
      "name": "[NAME REDACTED]",
      "email": "[EMAIL REDACTED]",
      "phone": "[PHONE REDACTED]"
    },
    "education": [
      {"degree": "B.Tech in Computer Science", "institution": "[INSTITUTION REDACTED]"}
    ],
    "experience": [
      {"company": "[COMPANY REDACTED]", "position": "Software Engineer"}
    ],
    "skills": {
      "technical": ["Python", "React"],
      "soft": ["Teamwork", "Communication"]
    }
  },
  "fit_scores": {
    "skills_match": 80,
    "experience_relevance": 60,
    "education_match": 90,
    "tenure_stability": 80,
    "growth_trajectory": 90,
    "total_fit": 78.5
  },
  "shortlisted": true
}
```

---

## ğŸ¤ Credits

- `pdfplumber`, `spaCy`, `json`, `re`, `datetime`
- Developed for NeoAI HRMS to automate candidate screening

---

## ğŸ“„ License

MIT License â€“ free for commercial and non-commercial use.

